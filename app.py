
import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import faiss
import numpy as np
import os
import torch

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data_path = 'book_data.csv'  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —É–∫–∞–∑–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ
books_df = pd.read_csv(data_path)

# –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞
books_df = books_df[books_df['annotation'].apply(lambda x: len(str(x)) > 50)]

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model_name = 'cointegrated/rubert-tiny2'  # –ú–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞
model = SentenceTransformer(model_name)  # –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–æ–¥–µ–ª–∏
model.eval()  # –ü–µ—Ä–µ–≤–æ–¥ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ FAISS
index_path = 'faiss_index.index'  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–Ω–¥–µ–∫—Å–∞
if os.path.exists(index_path):
    index = faiss.read_index(index_path)
else:
    st.write("–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")


def search_books(query, author_query=None, top_k=5):
    results = []

    # –ï—Å–ª–∏ –≤–≤–µ–¥–µ–Ω —Ç–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä
    if author_query and not query:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–Ω–∏–≥–∏ –ø–æ –∞–≤—Ç–æ—Ä—É
        filtered_books = books_df[books_df['author'].str.contains(author_query.strip(), case=False, na=False)]

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ top_k
        for _, row in filtered_books.head(top_k).iterrows():  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ top_k –∑–∞–ø–∏—Å–µ–π
            results.append({
                'cover_image': row['image_url'],
                'author': row['author'],
                'title': row['title'],
                'annotation': row['annotation'],
                'similarity_score': None  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º None, –ø–æ—Å–∫–æ–ª—å–∫—É –ø–æ–∏—Å–∫ –ø–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
            })
    else:
        # –ü–æ–∏—Å–∫ –ø–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º, –µ—Å–ª–∏ –≤–≤–µ–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ
        query_embedding = model.encode(query, convert_to_tensor=True).cpu().numpy().reshape(1, -1)
        distances, indices = index.search(query_embedding, top_k)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        for idx, score in zip(indices[0], distances[0]):
            author = books_df.iloc[idx]['author']

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∏–ª—å—Ç—Ä –ø–æ –∞–≤—Ç–æ—Ä—É
            if author_query is None or (author_query is not None and author_query.strip().lower() in author.strip().lower()):
                title = books_df.iloc[idx]['title']
                annotation = books_df.iloc[idx]['annotation']
                cover_image = books_df.iloc[idx]['image_url']

                if pd.notna(author) and pd.notna(title):  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∞–≤—Ç–æ—Ä–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è
                    results.append({
                        'cover_image': cover_image,
                        'author': author,
                        'title': title,
                        'annotation': annotation,
                        'similarity_score': score  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—É—Å—Ç
                    })

    return pd.DataFrame(results)


# Streamlit app setup
st.title("üìö find my book")
st.subheader("—É–º–Ω—ã–π –ø–æ–∏—Å–∫ –∫–Ω–∏–≥")

# –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
user_query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞")
author_query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)")
top_k = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞", min_value=1, value=3, step=1)

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–∏—Å–∫–∞
if st.button("–ù–∞–π—Ç–∏"):
    if user_query or author_query:
        results_df = search_books(user_query, author_query if author_query else None, top_k)

        if not results_df.empty:
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ª—É—á—à–µ –≤—Å–µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∑–∞–ø—Ä–æ—Å—É:")
            for index, row in results_df.iterrows():
                col1, col2 = st.columns([1, 2])  # –°–æ–∑–¥–∞–µ–º 2 –∫–æ–ª–æ–Ω–∫–∏
                with col1:
                    if row['cover_image']:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±–ª–æ–∂–∫—É
                        st.image(row['cover_image'], use_column_width=True)
                with col2:
                    st.subheader(row['title'])
                    st.write(f"<strong>–ê–≤—Ç–æ—Ä:</strong> {row['author']}", unsafe_allow_html=True)
                    st.write(f"<strong>–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è:</strong> {row['annotation']}", unsafe_allow_html=True)
                    if row['similarity_score'] is not None:  # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ None
                        st.write(f"<strong>–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é:</strong> {row['similarity_score']:.2f}%", unsafe_allow_html=True)
        else:
            st.write("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–Ω–∏–≥ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
    else:
        st.write("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ –∏–ª–∏ –∞–≤—Ç–æ—Ä–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞")
