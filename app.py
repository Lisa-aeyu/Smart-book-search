
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import faiss
import os
import streamlit as st
import numpy as np

@st.cache_data  # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
def load_data(data_path):
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    books_df = pd.read_csv(data_path)
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞
    books_df = books_df[books_df['annotation'].apply(lambda x: len(str(x)) > 50)]
    return books_df

@st.cache_resource  # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
def load_model(model_name):
    model = SentenceTransformer(model_name)
    model.eval()  # –ü–µ—Ä–µ–≤–æ–¥ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
    return model

# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–Ω–Ω—ã—Ö –∏ –∏–Ω–¥–µ–∫—Å–∞
data_path = 'book_data.csv'
index_path = 'faiss_index.index'  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–Ω–¥–µ–∫—Å–∞

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –º–æ–¥–µ–ª—å
books_df = load_data(data_path)
model = load_model('cointegrated/rubert-tiny2')  # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å FAISS
if os.path.exists(index_path):
    index = faiss.read_index(index_path)
else:
    st.write("–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

def search_books(query, author_query=None, top_k=5, search_mode='symmetric'):
    results = []

    # –ï—Å–ª–∏ –≤–≤–µ–¥–µ–Ω —Ç–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä
    if author_query and not query:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–Ω–∏–≥–∏ –ø–æ –∞–≤—Ç–æ—Ä—É
        filtered_books = books_df[books_df['author'].str.contains(author_query.strip(), case=False, na=False)]

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ top_k
        for _, row in filtered_books.head(top_k).iterrows():
            results.append({
                'cover_image': row['image_url'],
                'author': row['author'],
                'title': row['title'],
                'annotation': row['annotation'],
                'similarity_score': None
            })
    else:
        # –ü–æ–∏—Å–∫ –ø–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º, –µ—Å–ª–∏ –≤–≤–µ–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ
        query_embedding = model.encode(query, convert_to_tensor=True).cpu().numpy().reshape(1, -1)

        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
        annotation_embeddings = index.reconstruct_n(0, books_df.shape[0])

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        distances = util.pytorch_cos_sim(query_embedding, annotation_embeddings)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤
        distances = distances.cpu().numpy().flatten()
        indices = np.argsort(-distances)[:top_k]  # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã top_k —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        for idx in indices:
            score = distances[idx]
            author = books_df.iloc[idx]['author']
            title = books_df.iloc[idx]['title']
            annotation = books_df.iloc[idx]['annotation']
            cover_image = books_df.iloc[idx]['image_url']

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∏–ª—å—Ç—Ä –ø–æ –∞–≤—Ç–æ—Ä—É
            if author_query is None or (author_query.strip().lower() in author.strip().lower()):
                if pd.notna(author) and pd.notna(title):
                    results.append({
                        'cover_image': cover_image,
                        'author': author,
                        'title': title,
                        'annotation': annotation,
                        'similarity_score': score.item()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
                    })

    return pd.DataFrame(results)

# Streamlit app setup
st.title("üìö find my book")
st.subheader("—É–º–Ω—ã–π –ø–æ–∏—Å–∫ –∫–Ω–∏–≥")

# –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
user_query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞")
author_query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)")
top_k = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞", min_value=1, value=3, step=1)

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–∏—Å–∫–∞
if st.button("–ù–∞–π—Ç–∏"):
    if user_query or author_query:
        results_df = search_books(user_query, author_query if author_query else None, top_k)

        if not results_df.empty:
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ª—É—á—à–µ –≤—Å–µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∑–∞–ø—Ä–æ—Å—É:")
            for index, row in results_df.iterrows():
                col1, col2 = st.columns([1, 2])  # –°–æ–∑–¥–∞–µ–º 2 –∫–æ–ª–æ–Ω–∫–∏
                with col1:
                    if row['cover_image']:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±–ª–æ–∂–∫—É
                        st.image(row['cover_image'], use_column_width=True)
                with col2:
                    st.subheader(row['title'])
                    st.write(f"<strong>–ê–≤—Ç–æ—Ä:</strong> {row['author']}", unsafe_allow_html=True)
                    st.write(f"<strong>–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è:</strong> {row['annotation']}", unsafe_allow_html=True)
                    if row['similarity_score'] is not None:  # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ None
                        st.write(f"<strong>Similarity score:</strong> {row['similarity_score']:.2f}", unsafe_allow_html=True)
        else:
            st.write("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–Ω–∏–≥ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
    else:
        st.write("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ –∏–ª–∏ –∞–≤—Ç–æ—Ä–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞")
